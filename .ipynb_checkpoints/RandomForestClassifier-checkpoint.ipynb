{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.utils import Bunch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn import svm\n",
    "import cv2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_files(container_path, dimension=(64, 64)):\n",
    "    \"\"\"\n",
    "    Load image files with categories as subfolder names \n",
    "    which performs like scikit-learn sample dataset\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    container_path : string or unicode\n",
    "        Path to the main folder holding one subfolder per category\n",
    "    dimension : tuple\n",
    "        size to which image are adjusted to\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Bunch\n",
    "    \"\"\"\n",
    "    image_dir = Path(container_path)\n",
    "    folders = [directory for directory in image_dir.iterdir() if directory.is_dir()]\n",
    "    categories = [fo.name for fo in folders]\n",
    "\n",
    "    descr = \"A image classification dataset\"\n",
    "    images = []\n",
    "    flat_data = []\n",
    "    na=[]\n",
    "    id=[]\n",
    "    target = []\n",
    "    for i, direc in enumerate(folders):\n",
    "        for file in direc.iterdir():\n",
    "            cfile=str(file).replace('\\\\',\"/\")\n",
    "            \n",
    "            img = cv2.imread(cfile)\n",
    "#             print(img)\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            img_resized = resize(gray, dimension, anti_aliasing=True, mode='reflect')\n",
    "            flat_data.append(img_resized.flatten()) \n",
    "           \n",
    "            target.append(i)\n",
    "    flat_data = np.array(flat_data)\n",
    "    target = np.array(target)\n",
    "   \n",
    "\n",
    "    return Bunch(data=flat_data, \n",
    "                 target=target,\n",
    "                 target_names=categories,\n",
    "                 images=images,\n",
    "                 DESCR=descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset = load_image_files(\"outdata/\")\n",
    "\n",
    "test=load_image_files('fdklfd.cg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_dataset.images[100])\n",
    "plt.show()\n",
    "print(image_dataset.target[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(image_dataset.data, image_dataset.target, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n",
    "classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "#Reverse factorize (converting y_pred from 0s,1s and 2s to Iris-setosa, Iris-versicolor and Iris-virginica\n",
    "# reversefactor = dict(zip(range(3),definitions))\n",
    "# y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "# y_pred = np.vectorize(reversefactor.get)(y_pred)\n",
    "# # Making the Confusion Matrix\n",
    "# print(pd.crosstab(y_test, y_pred, rownames=['Actual Species'], colnames=['Predicted Species']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "s=0\n",
    "print(len(y_pred))\n",
    "for i, j in zip(y_pred, y_test):\n",
    "    if i!=j:\n",
    "        s+=1\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-7c37b70a9480>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'randomforestmodel.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "print(list(zip(dataset.columns[0:4], classifier.feature_importances_)))\n",
    "joblib.dump(classifier, 'randomforestmodel.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "#img = cv2.imread(\"test.png\")\n",
    "k='f47656e35afbe2d1f1dff886c4139235.png'\n",
    "img = cv2.imread(k)\n",
    "blurred = cv2.blur(img, (3,3))\n",
    "canny = cv2.Canny(blurred, 64, 64)\n",
    "\n",
    "## find the non-zero min-max coords of canny\n",
    "pts = np.argwhere(canny>0)\n",
    "y1,x1 = pts.min(axis=0)\n",
    "y2,x2 = pts.max(axis=0)\n",
    "\n",
    "## crop the region\n",
    "cropped = img[y1:y2, x1:x2]\n",
    "cv2.imwrite(\"croppss.png\", cropped)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Englis_digit\\trainingSet\\0\n",
      "Englis_digit\\trainingSet\\1\n",
      "Englis_digit\\trainingSet\\2\n",
      "Englis_digit\\trainingSet\\3\n",
      "Englis_digit\\trainingSet\\4\n",
      "Englis_digit\\trainingSet\\5\n",
      "Englis_digit\\trainingSet\\6\n",
      "Englis_digit\\trainingSet\\7\n",
      "Englis_digit\\trainingSet\\8\n",
      "Englis_digit\\trainingSet\\9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "import cv2\n",
    "image_dir = Path(\"Englis_digit/trainingSet/\")\n",
    "folders = [directory for directory in image_dir.iterdir() if directory.is_dir()]\n",
    "categories = [fo.name for fo in folders]\n",
    "\n",
    "descr = \"A image classification dataset\"\n",
    "images = []\n",
    "flat_data = []\n",
    "target = []\n",
    "for i, direc in enumerate(folders):\n",
    "    k=str(direc)\n",
    "    print(direc)\n",
    "    for file in direc.iterdir():\n",
    "        img = imread(file)\n",
    "#         image = cv2.imread('01_0001_0_08_0916_1990_1.png')\n",
    "        invert = cv2.bitwise_not(img) # OR\n",
    "        b=str(file)\n",
    "        c=b.replace(str(image_dir),\"\")\n",
    "        d=\"Englis_digit/tset\"+c\n",
    "\n",
    "        \n",
    "        blurred = cv2.blur(invert, (3,3))\n",
    "        canny = cv2.Canny(blurred, 50, 200)\n",
    "\n",
    "        ## find the non-zero min-max coords of canny\n",
    "        pts = np.argwhere(canny>0)\n",
    "        y1,x1 = pts.min(axis=0)\n",
    "        y2,x2 = pts.max(axis=0)\n",
    "\n",
    "        ## crop the region\n",
    "        cropped = invert[y1:y2, x1:x2]\n",
    "        cv2.imwrite(d, cropped)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# each Image squrre view\n",
    "# tagged = cv2.rectangle(img.copy(), (x1,y1), (x2,y2), (0,255,0), 3, cv2.LINE_AA)\n",
    "# cv2.imshow(\"tagged\", tagged)\n",
    "# cv2.waitKey()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b='abd\\K\\Z'\n",
    "c=b.replace('\\\\',\"/\")\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SAHIN\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-25b92e4d5dec>\", line 1, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"C:\\Users\\SAHIN\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 99, in <module>\n",
      "    from tensorflow_core import *\n",
      "  File \"C:\\Users\\SAHIN\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 32, in <module>\n",
      "    from tensorflow._api.v1 import app\n",
      "ModuleNotFoundError: No module named 'tensorflow._api.v1'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SAHIN\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ModuleNotFoundError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SAHIN\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\SAHIN\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\SAHIN\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\SAHIN\\Anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\SAHIN\\Anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\SAHIN\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\SAHIN\\Anaconda3\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\SAHIN\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\SAHIN\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\SAHIN\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\SAHIN\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 32, in <module>\n",
      "    from tensorflow._api.v1 import app\n",
      "ModuleNotFoundError: No module named 'tensorflow._api.v1'\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow._api.v1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows in Laptop is:  1\n",
      "\n",
      "Printing each laptop record\n",
      "Id =  2\n",
      "C:/xampp/htdocs/sign_src/doc_signs/95d13c3627d73a258327602cd9050878.png\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "\n",
    "try:\n",
    "    connection = mysql.connector.connect(host='localhost',\n",
    "                                         database='data',\n",
    "                                         user='root',\n",
    "                                         password='')\n",
    "\n",
    "    sql_select_Query = \"SELECT * FROM `check_image` ORDER BY `id` DESC LIMIT 1\"\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(sql_select_Query)\n",
    "    records = cursor.fetchall()\n",
    "    print(\"Total number of rows in Laptop is: \", cursor.rowcount)\n",
    "\n",
    "    print(\"\\nPrinting each laptop record\")\n",
    "    for row in records:\n",
    "        print(\"Id = \", row[0], )\n",
    "        k=\"C:/xampp/htdocs/sign_src/\"+row[1]\n",
    "        print(k)\n",
    "\n",
    "except Error as e:\n",
    "    print(\"Error reading data from MySQL table\", e)\n",
    "finally:\n",
    "    if (connection.is_connected()):\n",
    "        connection.close()\n",
    "        cursor.close()\n",
    "#         print(\"MySQL connection is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23_10_19_00_18_33.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import cv2\n",
    "t = time.localtime()\n",
    "current_time = time.strftime(\"%d_%m_%y_%H_%M_%S\", t)\n",
    "current_time+='.png'\n",
    "\n",
    "img = cv2.imread('f47656e35afbe2d1f1dff886c4139235.png')\n",
    "cv2.imwrite('BONNO/'+current_time, img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YWJjMTIzIT8kKiYoKSctPUB+\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "\n",
    "data = \"abc123!?$*&()'-=@~\"\n",
    "\n",
    "# Standard Base64 Encoding\n",
    "encodedBytes = base64.b64encode(data.encode(\"utf-8\"))\n",
    "encodedStr = str(encodedBytes, \"utf-8\")\n",
    "\n",
    "print(encodedStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/abdcdd\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'form' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-cf7a953c281f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'images/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msecure_filename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mfoto\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphoto_upload\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'form' is not defined"
     ]
    }
   ],
   "source": [
    "from werkzeug import secure_filename\n",
    "b='abdcdd'\n",
    "sfname = 'images/'+str(secure_filename(b))\n",
    "print(sfname)\n",
    "foto = form.photo_upload.data.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1\n",
      "11\n",
      "111\n",
      "1111\n",
      "11111\n",
      "111111\n",
      "1111111\n",
      "11111111\n",
      "111111111\n",
      "1111111111\n",
      "11111111111\n",
      "111111111111\n",
      "1111111111111\n",
      "11111111111111\n",
      "111111111111111\n",
      "1111111111111111\n",
      "11111111111111111\n",
      "111111111111111111\n",
      "1111111111111111111\n",
      "11111111111111111111\n",
      "111111111111111111111\n",
      "1111111111111111111111\n",
      "11111111111111111111111\n",
      "111111111111111111111111\n",
      "1111111111111111111111111\n",
      "11111111111111111111111111\n",
      "111111111111111111111111111\n",
      "1111111111111111111111111111\n",
      "11111111111111111111111111111\n",
      "111111111111111111111111111111\n",
      "1111111111111111111111111111111\n",
      "11111111111111111111111111111111\n",
      "111111111111111111111111111111111\n",
      "1111111111111111111111111111111111\n",
      "11111111111111111111111111111111111\n",
      "111111111111111111111111111111111111\n",
      "1111111111111111111111111111111111111\n",
      "11111111111111111111111111111111111111\n"
     ]
    }
   ],
   "source": [
    "s=''\n",
    "for i in range(39):\n",
    "    for j in range(i):\n",
    "        s=s+'1'\n",
    "#         print('0',end='')\n",
    "    print(s)\n",
    "    s=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# define the name of the directory to be created\n",
    "path = 'C:/Users/SAHIN/Documents/sahin/bbonno/'\n",
    "\n",
    "\n",
    "s=''\n",
    "for i in range(40):\n",
    "    for j in range(i):\n",
    "        s=s+'1'\n",
    "    d=path+s\n",
    "    if not os.path.exists(d):\n",
    "        os.mkdir(d)\n",
    "        s=''\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "print(len('11111111111111111111111111111111111111'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "import cv2\n",
    "file='500_26.jpg'\n",
    "img = cv2.imread(file)\n",
    "# b=str(file)\n",
    "# c=b.replace(str(image_dir),\"\")\n",
    "# d=\"E_alphabet\"+c\n",
    "\n",
    "\n",
    "blurred = cv2.blur(img, (3,3))\n",
    "canny = cv2.Canny(blurred, 50, 200)\n",
    "\n",
    "## find the non-zero min-max coords of canny\n",
    "pts = np.argwhere(canny>0)\n",
    "y1,x1 = pts.min(axis=0)\n",
    "y2,x2 = pts.max(axis=0)\n",
    "\n",
    "## crop the region\n",
    "cropped = img[y1:y2, x1:x2]\n",
    "cv2.imwrite('abcd.png', cropped)\n",
    "\n",
    "\n",
    "\n",
    "# each Image squrre view\n",
    "tagged = cv2.rectangle(img.copy(), (x1,y1), (x2,y2), (0,255,0), 3, cv2.LINE_AA)\n",
    "cv2.imshow(\"tagged\", tagged)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "file='01_0001_0_11_0916_1917_16.png'\n",
    "dimension=(64, 64)\n",
    "img = cv2.imread(file)\n",
    "img_resized = cv2.resize(img, dimension)\n",
    "\n",
    "cv2.imwrite('d.png', img_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
